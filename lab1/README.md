# Лабораторная работа 1: Dockerfile

## Описание задания

Написать два Dockerfile — плохой и хороший. Плохой должен работать корректно, но содержать не менее 3 "bad practices". В хорошем они должны быть исправлены.

## Файлы

- [`Dockerfile.bad`](../Dockerfile.bad) — Dockerfile с плохими практиками (но рабочий)
- [`Dockerfile.good`](../Dockerfile.good) — Dockerfile с исправленными практиками
- [`.dockerignore`](../.dockerignore) — исключения для Docker build

## Приложение

Веб-приложение на базе **Litestar framework** для управления событиями и продажей билетов. Приложение использует:
- Python 3.12
- Litestar (асинхронный веб-фреймворк)
- PostgreSQL (база данных)
- Redis (кэширование)

---

## Плохие практики в Dockerfile.bad

### 1. Использование тега `latest`

**Плохо:**
```dockerfile
FROM python:latest
```

**Почему плохо:**
- Непредсказуемость: `latest` может измениться в любой момент
- Нарушается воспроизводимость сборок — сегодня это Python 3.12, завтра 3.13
- Разные разработчики могут получить разные версии
- Невозможно откатиться к предыдущей рабочей версии

**Как исправлено в Dockerfile.good:**
```dockerfile
FROM python:3.12-slim-bookworm
```
- Конкретная версия Python (3.12)
- Конкретная версия Debian (bookworm)
- Slim-образ для уменьшения размера (~150MB vs ~1GB)

---

### 2. Множественные RUN команды

**Плохо:**
```dockerfile
RUN apt-get update
RUN apt-get install -y curl
RUN apt-get install -y vim
RUN apt-get install -y nano
RUN apt-get install -y git
RUN apt-get install -y build-essential
```

**Почему плохо:**
- Каждая RUN команда создает новый слой в образе
- Увеличивается итоговый размер образа
- Замедляется сборка из-за множества слоёв
- `apt-get update` и `apt-get install` в разных слоях — кэш update может устареть

**Как исправлено в Dockerfile.good:**
```dockerfile
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*
```
- Одна RUN команда = один слой
- Очистка кэша APT в той же команде (не попадает в слой)

---

### 3. Установка ненужных пакетов

**Плохо:**
```dockerfile
RUN apt-get install -y vim
RUN apt-get install -y nano
RUN apt-get install -y git
RUN apt-get install -y build-essential
```

**Почему плохо:**
- Увеличение размера образа на сотни MB
- Увеличение поверхности атаки (больше пакетов = больше потенциальных уязвимостей)
- vim/nano не нужны в production контейнере — для отладки используют `docker exec`
- git не нужен, т.к. код копируется через COPY
- build-essential не нужен — UV скачивает готовые wheels

**Как исправлено в Dockerfile.good:**
```dockerfile
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*
```
- Установлен только `curl` (нужен для HEALTHCHECK)

---

### 4. Отсутствие очистки кэша APT

**Плохо:**
```dockerfile
RUN apt-get update
RUN apt-get install -y curl
# кэш остаётся в образе
```

**Почему плохо:**
- Кэш APT остается в финальном образе
- Увеличение размера образа на 50-200 MB
- Лишние данные в production

**Как исправлено в Dockerfile.good:**
```dockerfile
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*
```
- Очистка `rm -rf /var/lib/apt/lists/*` в той же RUN команде
- Кэш не попадает в финальный слой

---

### 5. Неправильный порядок COPY (плохое кэширование)

**Плохо:**
```dockerfile
WORKDIR /app
COPY . .
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv
RUN uv sync
```

**Почему плохо:**
- При изменении ЛЮБОГО файла кода инвалидируется кэш
- Зависимости переустанавливаются даже если не изменились
- Медленная пересборка при разработке (каждый раз 1-2 минуты на установку зависимостей)

**Как исправлено в Dockerfile.good:**
```dockerfile
# Сначала копируем UV
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

# Затем только файлы зависимостей
COPY pyproject.toml uv.lock* ./

# Устанавливаем зависимости (кэшируется отдельно)
RUN uv sync --no-dev --frozen

# В конце копируем код
COPY . .
```
- Зависимости кэшируются отдельным слоем
- При изменении кода зависимости не переустанавливаются
- Пересборка занимает секунды вместо минут

---

### 6. Использование chmod 777

**Плохо:**
```dockerfile
RUN chmod 777 /app/app/scripts/entry
RUN chmod 777 /app
```

**Почему плохо:**
- `777` = полные права для ВСЕХ пользователей (read, write, execute)
- Критическая уязвимость безопасности
- Любой процесс в контейнере может изменить/удалить файлы
- Нарушение принципа наименьших привилегий

**Как исправлено в Dockerfile.good:**
- Убраны избыточные chmod команды
- Скрипт entry уже имеет права на выполнение в репозитории

---

### 7. Установка dev-зависимостей в production

**Плохо:**
```dockerfile
RUN uv sync
```

**Почему плохо:**
- Устанавливаются dev-зависимости (pytest, ruff, mypy, etc.)
- Увеличение размера образа на 100+ MB
- Потенциальные уязвимости в dev-пакетах
- Лишний код в production

**Как исправлено в Dockerfile.good:**
```dockerfile
RUN uv sync --no-dev --frozen
```
- `--no-dev`: только production зависимости
- `--frozen`: использовать lock-файл без изменений (воспроизводимость)

---

### 8. Отсутствие EXPOSE и HEALTHCHECK

**Плохо:**
```dockerfile
# EXPOSE отсутствует
# HEALTHCHECK отсутствует
```

**Почему плохо:**
- Неясно какой порт использует приложение
- Плохая документация образа
- Оркестраторы (Docker Swarm, Kubernetes) не могут проверить здоровье контейнера
- Проблемы с автоматическим обнаружением портов

**Как исправлено в Dockerfile.good:**
```dockerfile
EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
```
- Явное указание порта
- Проверка здоровья каждые 30 секунд
- Автоматический перезапуск при сбоях (в Docker Swarm/Compose)

---

## Сравнение размеров образов

```bash
# Сборка плохого образа
docker build -f Dockerfile.bad -t app:bad .

# Сборка хорошего образа
docker build -f Dockerfile.good -t app:good .

# Сравнение размеров
docker images | grep app
```

| Образ | Размер |
|-------|--------|
| app:bad | ~1.2 GB |
| app:good | ~450 MB |

**Разница: ~750 MB (в 2.5+ раза меньше)**

---

## Плохие практики использования контейнеров

### 1. Хранение секретов в образе

**Плохая практика:**
```dockerfile
ENV DATABASE_PASSWORD=super_secret_password
COPY secrets.json /app/secrets.json
```

**Почему плохо:**
- Секреты остаются в слоях образа навсегда
- Любой с доступом к образу может извлечь секреты через `docker history` или `docker save`
- При публикации образа в registry секреты становятся публичными
- Невозможно ротировать секреты без пересборки образа

**Как правильно:**
- Использовать переменные окружения при запуске: `docker run -e PASSWORD=xxx`
- Использовать Docker secrets (в Swarm) или Kubernetes secrets
- Монтировать секреты как volumes: `docker run -v ./secrets:/run/secrets:ro`

---

### 2. Запуск контейнера как "виртуальной машины"

**Плохая практика:**
- Запуск нескольких процессов в одном контейнере (nginx + python + cron)
- Использование systemd/supervisord внутри контейнера
- SSH-доступ в контейнер для отладки
- Ручное обновление приложения внутри работающего контейнера

**Почему плохо:**
- Нарушается принцип "один контейнер = один процесс"
- Сложнее масштабировать отдельные компоненты
- Логи смешиваются, сложнее отлаживать
- Теряется воспроизводимость — контейнер "дрейфует" от образа
- Невозможно использовать оркестрацию (Kubernetes, Swarm)

**Как правильно:**
- Один процесс на контейнер
- Для нескольких сервисов использовать Docker Compose
- Для отладки: `docker exec -it container bash`
- Для обновления: пересобрать образ и перезапустить контейнер

---

## Когда НЕ стоит использовать контейнеры

### 1. Приложения с прямым доступом к железу

**Примеры:**
- Драйверы устройств и kernel modules
- Приложения для работы с GPU (частично решается через nvidia-docker, но с overhead)
- Системы управления промышленным оборудованием (PLC, SCADA)
- Приложения, требующие доступа к специфичным устройствам (/dev/*)

**Почему не подходит:**
- Контейнеры изолируют от железа по дизайну
- Проброс устройств (`--device`) снижает изоляцию и усложняет деплой
- Драйверы должны быть в ядре хоста, а не в контейнере
- Сложности с совместимостью версий драйверов

**Альтернативы:**
- Виртуальные машины с полным проброса устройств (PCI passthrough)
- Bare metal установка
- Специализированные решения (nvidia-docker для GPU)

---

### 2. Десктопные GUI-приложения

**Примеры:**
- IDE и редакторы кода (VS Code, IntelliJ)
- Графические редакторы (Photoshop, GIMP)
- Браузеры (хотя есть исключения для тестирования)
- Игры

**Почему не подходит:**
- Контейнеры не имеют доступа к X11/Wayland по умолчанию
- Проброс дисплея сложен и небезопасен (`-e DISPLAY -v /tmp/.X11-unix`)
- Производительность графики значительно снижается
- Звук требует дополнительной настройки (PulseAudio)
- UX страдает — задержки, артефакты

**Альтернативы:**
- Нативная установка
- Flatpak/Snap (песочница для десктопных приложений)
- Виртуальные машины с GPU passthrough

---

## Запуск приложения

### Сборка образа

```bash
# Хороший образ
docker build -f Dockerfile.good -t event-app:latest .

# Плохой образ (для сравнения)
docker build -f Dockerfile.bad -t event-app:bad .
```

### Запуск контейнера

```bash
docker run -d \
  --name event-app \
  -p 8000:8000 \
  -v app-logs:/app/logs \
  -e DATABASE_URL=postgresql://user:pass@host:5432/db \
  event-app:latest
```

### Проверка работы

```bash
# Статус контейнера
docker ps

# Логи
docker logs -f event-app

# Health check
curl http://localhost:8000/health
```

